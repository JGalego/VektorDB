{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d34ce27-961d-4215-88b3-6f3cea037e75",
   "metadata": {},
   "source": [
    "## Amazon Bedrock meets VektorDB ‚õ∞Ô∏èüèπ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd3c885-522d-4666-a0d5-fda1251f3a1f",
   "metadata": {},
   "source": [
    "In this example, we'll use the [Grade School Math 8K](https://huggingface.co/datasets/openai/gsm8k) (GSM8K) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668c96b1-95be-4037-81d7-517c6cc2a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Number of samples we want to process\n",
    "N_SAMPLES = 100\n",
    "\n",
    "# Load dataset\n",
    "# https://huggingface.co/datasets/openai/gsm8k\n",
    "ds = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")[:N_SAMPLES]\n",
    "questions = ds['question']\n",
    "answers = ds['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a64016-a5bf-4196-8770-038387b9db83",
   "metadata": {},
   "source": [
    "which contains \"high quality linguistically diverse grade school math word problems\" in the form of `question-answer` pairs like the one shown below\n",
    "\n",
    "```\n",
    "### Question\n",
    "\n",
    "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May.\n",
    "How many clips did Natalia sell altogether in April and May?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
    "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May. #### 72\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c278faf-2628-407b-86f0-0364477cf495",
   "metadata": {},
   "source": [
    "Our goal is to turn these `question-answer` pairs into embeddings, store them in VektorDB and perform some operations.\n",
    "\n",
    "> üí° **Embeddings** are just numerical representations of a piece of information, usually in the form of vectors. You can turn any kind of data into embeddings (e.g. [üí¨](https://huggingface.co/blog/getting-started-with-embeddings) [üñºÔ∏è](https://www.pinecone.io/learn/series/image-search/) [üîä](https://huggingface.co/blog/cappuch/audio-embedding-wtf) [üéûÔ∏è](https://github.com/iejMac/clip-video-encode) [ü¶†](https://www.biorxiv.org/content/10.1101/2023.11.28.568918v1)) and they'll *preserve* the meaning of the original data. **If you want to learn more about embeddings**, check out [Mapping Embeddings: from meaning to vectors and back](https://jgalego.github.io/MappingEmbeddings).\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:2000/1*SYiW1MUZul1NvL1kc1RxwQ.png\" width=\"70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d8d8c4-364e-4698-9376-a0c92d284e50",
   "metadata": {},
   "source": [
    "Let's define a helper function to call [Cohere Embed](https://aws.amazon.com/bedrock/cohere-command-embed/) models via [Amazon Bedrock](https://aws.amazon.com/bedrock/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695d4a11-c40b-4e2d-98d1-ca2f40f331d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "def embed(texts: list, model_id=\"cohere.embed-english-v3\"):\n",
    "    \"\"\"Generates embeddings for an array of strings using Cohere Embed models.\"\"\"\n",
    "    model_provider = model_id.split('.')[0]\n",
    "    assert model_provider == \"cohere\", \\\n",
    "        f\"Invalid model provider (Got: {model_provider}, Expected: cohere)\"\n",
    "\n",
    "    # Prepare payload\n",
    "    accept = \"*/*\"\n",
    "    content_type = \"application/json\"\n",
    "    body = json.dumps({\n",
    "        'texts': texts,\n",
    "        'input_type': \"search_document\"\n",
    "    })\n",
    "\n",
    "    # Call model\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body,\n",
    "        modelId=model_id,\n",
    "        accept=accept,\n",
    "        contentType=content_type\n",
    "    )\n",
    "\n",
    "    # Process response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body.get('embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f59b0e-e624-437e-bc06-1fa839606fa2",
   "metadata": {},
   "source": [
    "and use it to generate embeddings for a small subset of our data (answers only, for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd0a6f7-6352-4e60-ab11-32dadf9a2617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Text call limit for Cohere Embed models via Amazon Bedrock\n",
    "# https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-embed.html\n",
    "MAX_TEXTS_PER_CALL = 96\n",
    "\n",
    "embeddings = []\n",
    "for idx in tqdm(range(0, len(answers), MAX_TEXTS_PER_CALL), \"Generating embeddings\"):\n",
    "    embeddings += embed(answers[idx:idx+MAX_TEXTS_PER_CALL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d9782-69ed-4420-80cf-12fd596583d9",
   "metadata": {},
   "source": [
    "We are now ready to initialize VektorDB and start loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b2f512-4452-43c3-a6e6-aaf415d1b799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 22440.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from vektordb import ANNVectorDatabase\n",
    "from vektordb.types import Vector\n",
    "\n",
    "# Initialize database\n",
    "vector_db = ANNVectorDatabase()\n",
    "\n",
    "# Load embeddings into the database\n",
    "for idx in tqdm(range(len(embeddings)), \"Loading embeddings\"):\n",
    "    vector_db.insert(idx, Vector(embeddings[idx], {'answer': answers[idx][:20]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4e191-ee67-4669-a1c9-532ba221ffb6",
   "metadata": {},
   "source": [
    "As a sanity check, we can print a small sample of our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ba5608-7543-468a-8a4f-2dc4005f4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------+------------------------------------+\n",
      "| Key |           Data          |              Metadata              |\n",
      "+-----+-------------------------+------------------------------------+\n",
      "|  0  | [-0.00618 ... -0.00047] | {'answer': 'Natalia sold 48/2 = '} |\n",
      "|  1  | [-0.01997 ... -0.01791] | {'answer': 'Weng earns 12/60 = $'} |\n",
      "|  2  | [-0.00623 ... -0.0061 ] | {'answer': 'In the beginning, Be'} |\n",
      "|  3  | [-0.07849 ...  0.00721] | {'answer': 'Maila read 12 x 2 = '} |\n",
      "|  4  | [-0.01669 ...  0.01263] | {'answer': 'He writes each frien'} |\n",
      "|  5  |  [0.02484 ... 0.05185]  | {'answer': 'There are 80/100 * 1'} |\n",
      "|  6  | [-0.01807 ... -0.01859] | {'answer': 'He eats 32 from the '} |\n",
      "|  7  | [ 0.01265 ... -0.02016] | {'answer': 'To the initial 2 pou'} |\n",
      "|  8  | [-0.00504 ...  0.0143 ] | {'answer': 'Let S be the amount '} |\n",
      "|  9  | [-0.0239  ... -0.00905] | {'answer': 'She works 8 hours a '} |\n",
      "+-----+-------------------------+------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "vector_db.display(\n",
    "    np_format={\n",
    "        'edgeitems': 1,\n",
    "        'precision': 5,\n",
    "        'threshold': 3,\n",
    "        'suppress': True\n",
    "    },\n",
    "    keys=range(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90eeaf4-d8bd-402b-80de-a539a774a01e",
   "metadata": {},
   "source": [
    "Our VektorDB instance is backed by an implementation of [Approximate Nearest Neighbors](https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6) (ANN) search that uses [binary trees](https://en.wikipedia.org/wiki/Binary_tree) to represent different partitions/splits of the hyperspace.\n",
    "\n",
    "These partitions are generated by picking two vectors at random, finding the hyperplane equidistant between the two and then splitting the other points into `left` and `right` depending on which side they're on\n",
    "\n",
    "<img src=\"https://erikbern.com/assets/2015/09/tree-1-1024x793.png\" width=\"50%\"/>\n",
    "\n",
    "This process is repeated until we have *at most* `k` items in each node (partition)\n",
    "\n",
    "<img src=\"https://erikbern.com/assets/2015/09/tree-full-K-1024x793.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27de28-4a20-411d-9d14-6497bcedae7b",
   "metadata": {},
   "source": [
    "We can get better results by generating a *forest of trees** üå≥ and searching all of them, so let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28fc553-13b9-4da5-a015-a6fb97215aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set seed value for replication\n",
    "random.seed(42)\n",
    "\n",
    "# Plant a bunch of trees üèûÔ∏è\n",
    "vector_db.build(n_trees=3, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50bf06-5df5-4378-a8c5-e5a871504481",
   "metadata": {},
   "source": [
    "Here's a representation of the first tree in our *forest* (the nodes show the number of instances in each partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fad0a0c-6bed-4625-a71e-0e696a8f0591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       __________100______________                         \n",
      "                                                      /                           \\                        \n",
      "     ________________________________________________63______          __________37___________             \n",
      "    /                                                        \\        /                       \\            \n",
      "  _51__                                                    _12_      16____               ___21____        \n",
      " /     \\                                                  /    \\    /      \\             /         \\       \n",
      " 6    45____________________                             _7    5    2    _14___        _10_      _11_____  \n",
      "/ \\  /                      \\                           /  \\  / \\       /      \\      /    \\    /        \\ \n",
      "3 3  3           __________42_____________              4  3  2 3       5     _9     _5    5    4     ___7 \n",
      "                /                         \\            / \\             / \\   /  \\   /  \\  / \\  / \\   /    \\\n",
      "            ___18____               _____24____        2 2             3 2   6  3   4  1  2 3  3 1   6_   1\n",
      "           /         \\             /           \\                            / \\    / \\              /  \\   \n",
      "          _8_      _10_        ___11___      _13_                           3 3    1 3              2  4   \n",
      "         /   \\    /    \\      /        \\    /    \\                                                    / \\  \n",
      "         4   4    4    6_     6_      _5    5    8_                                                   3 1  \n",
      "        / \\ / \\  / \\  /  \\   /  \\    /  \\  / \\  /  \\                                                       \n",
      "        2 2 3 1  1 3  2  4   2  4    4  1  2 3  3  5                                                       \n",
      "                        / \\    / \\  / \\           / \\                                                      \n",
      "                        1 3    3 1  2 2           2 3                                                       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(vector_db.trees[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cbfc27-04a1-4ca0-b008-c5d6d75bbd79",
   "metadata": {},
   "source": [
    "Finally, we can run a query by simply searching the database for answers *similar* to a target question.\n",
    "\n",
    "We use [distance functions](https://weaviate.io/blog/distance-metrics-in-vector-search) like the ones shown below to quantify how similar two vectors are to one another.\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1200/1*FTVRr_Wqz-3_k6Mk6G4kew.png\" width=\"30%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51886987-ded8-4532-8df8-b9178cd2e44a",
   "metadata": {},
   "source": [
    "For instance, if we ask the first question in our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64997eb3-7fd8-4a6f-ba5f-1e7c222c141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = questions[0]\n",
    "print(\"\\nQuery:\", query, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70af5e5-fa8f-4195-8513-3cf7e674e707",
   "metadata": {},
   "source": [
    "we expect the answer with the same index (`0`) to be the top result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8015cdb9-2233-44c6-a56f-704aaf5f684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------+\n",
      "| Key |        Score        |\n",
      "+-----+---------------------+\n",
      "|  0  | 0.15148634752350043 |\n",
      "|  15 |  0.6105711817572272 |\n",
      "|  83 |  0.6823805943068366 |\n",
      "+-----+---------------------+\n"
     ]
    }
   ],
   "source": [
    "from vektordb.utils import print_similarity_scores\n",
    "\n",
    "# Run search and display similarity scores\n",
    "results = vector_db.search(embed([query])[0], 3)\n",
    "print_similarity_scores(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
